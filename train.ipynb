{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# public\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable as V\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# custom\n",
    "from model_layer import Vgg16_all_layer, Vgg19_all_layer, Res152_all_layer, Dense169_all_layer\n",
    "from generator import GeneratorResnet\n",
    "from dct import *\n",
    "# from utils import *\n",
    "from loader_checkpoint import *\n",
    "\n",
    "# logging\n",
    "import logging, json\n",
    "with open(\"logging_config.json\", \"rt\") as file:\n",
    "    config = json.load(file)\n",
    "logging.config.dictConfig(config)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ArgumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-11 13:30:37,766 - root - INFO - Namespace(DA=False, FA=True, RN=False, epochs=0, eps=10, iter=10000, iter_ckpt=False, model_type='vgg16')\n"
     ]
    }
   ],
   "source": [
    "## Loaded pretrained generator options\n",
    "parser0 = argparse.ArgumentParser(description='Transferable Perturbation via Frequency Manipulation')\n",
    "parser0.add_argument('--epochs', type=int, default=0, help='Model checkpoint epoch number')\n",
    "parser0.add_argument('--eps', type=int, default=10, help='Perturbation budget (0~255)')\n",
    "parser0.add_argument('--model_type', type=str, default='vgg16', help='Victim model: vgg16, vgg19, res152, dense169')\n",
    "parser0.add_argument('--RN', type=lambda x: (str(x).lower() == 'true'), default=False, help='If true, activating the Random Normalization module in training phase')\n",
    "parser0.add_argument('--DA', type=lambda x: (str(x).lower() == 'true'), default=False, help='If true, activating the Domain-agnostic Attention module in training phase')\n",
    "parser0.add_argument('--FA', type=lambda x: (str(x).lower() == 'true'), default=True, help='If true, activating the Frequency Augmentation module in training phase')\n",
    "parser0.add_argument('--iter_ckpt', type=lambda x: (str(x).lower() == 'true'), default=False, help='If true, Model checkpoint with iteration number')\n",
    "parser0.add_argument('--iter', type=int, default=10000, help='Save Model checkpoint iteration number')\n",
    "args0 = parser0.parse_args(args=[])\n",
    "logger.info(args0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-11 13:30:41,468 - root - INFO - Namespace(DA=False, FA=True, RN=False, batch_size=16, epochs=1, eps=10, iter=10000, iter_ckpt=False, lr=0.0002, model_type='vgg16', rho=0.5, sigma=16.0, train_dir='../dataset/imagenet/train')\n"
     ]
    }
   ],
   "source": [
    "## New generator training options\n",
    "parser = argparse.ArgumentParser(description='Transferable Perturbation via Frequency Manipulation')\n",
    "parser.add_argument('--train_dir', default='../dataset/imagenet/train', help='Path for imagenet training data')\n",
    "parser.add_argument('--batch_size', type=int, default=16, help='Batch size')\n",
    "parser.add_argument('--epochs', type=int, default=1, help='Number of training epochs')\n",
    "parser.add_argument('--lr', type=float, default=0.0002, help='Initial learning rate') # default=0.0002\n",
    "parser.add_argument('--eps', type=int, default=10, help='Perturbation budget (0~255)')\n",
    "parser.add_argument('--model_type', type=str, default='vgg16', help='Victim model: vgg16, vgg19, res152, dense169')\n",
    "parser.add_argument('--RN', type=lambda x: (str(x).lower() == 'true'), default=False, help='If true, activating the Random Normalization module in training phase')\n",
    "parser.add_argument('--DA', type=lambda x: (str(x).lower() == 'true'), default=False, help='If true, activating the Domain-agnostic Attention module in training phase')\n",
    "parser.add_argument('--FA', type=lambda x: (str(x).lower() == 'true'), default=True, help='If true, activating the Frequency Augmentation module in training phase')\n",
    "parser.add_argument(\"--rho\", type=float, default=0.5, help=\"Tuning factor\")\n",
    "parser.add_argument(\"--sigma\", type=float, default=16.0, help=\"Std of random noise\")\n",
    "parser.add_argument('--iter_ckpt', type=lambda x: (str(x).lower() == 'true'), default=False, help='If true, Model checkpoint with iteration number')\n",
    "parser.add_argument('--iter', type=int, default=10000, help='Save Model checkpoint iteration number')\n",
    "args = parser.parse_args(args=[])\n",
    "logger.info(args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def setup_seed(seed):\n",
    "#     random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed_all(seed)\n",
    "#     torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# setup_seed(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the victim classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.model_type == 'vgg16':\n",
    "    model = Vgg16_all_layer.Vgg16()\n",
    "    layer_idx = 16 # Maxpooling.3\n",
    "elif args.model_type == 'vgg19':\n",
    "    model = Vgg19_all_layer.Vgg19()\n",
    "    layer_idx = 18 # Maxpooling.3\n",
    "elif args.model_type == 'res152':\n",
    "    model = Res152_all_layer.Resnet152()\n",
    "    layer_idx = 5 # Conv3_8\n",
    "elif args.model_type == 'dense169':\n",
    "    model = Dense169_all_layer.Dense169()\n",
    "    layer_idx = 6 # Denseblock.2\n",
    "else:\n",
    "    raise Exception('Check the model_type')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the generative attack model/optimizer/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model, Optimizer\n",
    "\n",
    "### From scratch\n",
    "# netG = GeneratorResnet()\n",
    "# netG = nn.DataParallel(netG, device_ids=[0,1,2,3]) # multi-GPU\n",
    "# netG = netG.to(device)\n",
    "\n",
    "### Load the pretrained generator\n",
    "netG = load_gan(args0, 'imagenet')\n",
    "netG = netG.to(device)\n",
    "\n",
    "optimG = optim.Adam(netG.parameters(), lr=args.lr, betas=(0.5, 0.999))\n",
    "\n",
    "\n",
    "if args.RN and args.DA:\n",
    "    save_checkpoint_suffix = 'BIA+RN+DA'\n",
    "elif args.RN:\n",
    "    save_checkpoint_suffix = 'BIA+RN'\n",
    "elif args.DA:\n",
    "    save_checkpoint_suffix = 'BIA+DA'\n",
    "elif args.FA:\n",
    "    save_checkpoint_suffix = 'BIA+FA'\n",
    "else:\n",
    "    save_checkpoint_suffix = 'BIA'\n",
    "\n",
    "# Data, Transform\n",
    "scale_size = 256\n",
    "img_size = 224\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(scale_size),\n",
    "    transforms.CenterCrop(img_size),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dir = args.train_dir\n",
    "train_set = datasets.ImageFolder(train_dir, data_transform)\n",
    "train_loader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_size = len(train_set)\n",
    "logger.info('Training data size:', train_size)\n",
    "\n",
    "def default_normalize(t):\n",
    "    t[:, 0, :, :] = (t[:, 0, :, :] - 0.485) / 0.229\n",
    "    t[:, 1, :, :] = (t[:, 1, :, :] - 0.456) / 0.224\n",
    "    t[:, 2, :, :] = (t[:, 2, :, :] - 0.406) / 0.225\n",
    "    return t\n",
    "\n",
    "def normalize(t, mean, std):\n",
    "    t[:, 0, :, :] = (t[:, 0, :, :] - mean) / std\n",
    "    t[:, 1, :, :] = (t[:, 1, :, :] - mean) / std\n",
    "    t[:, 2, :, :] = (t[:, 2, :, :] - mean) / std\n",
    "    return t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint_dir = 'saved_models/{}'.format(args.model_type)\n",
    "if not os.path.exists(save_checkpoint_dir):\n",
    "    os.makedirs(save_checkpoint_dir)\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    running_loss = 0\n",
    "    for i, (img, _) in enumerate(train_loader):\n",
    "        img = img.to(device)\n",
    "        netG.train()\n",
    "        optimG.zero_grad()\n",
    "        \n",
    "        if args.FA and i%2==1:\n",
    "            gauss = (torch.randn(img.size()[0], 3, img_size, img_size) * (args.sigma / 255)).to(device)\n",
    "            mask = (torch.rand_like(img) * 2 * args.rho + 1 - args.rho).to(device)\n",
    "            \n",
    "            img_dct = dct_2d(img + gauss).to(device)\n",
    "            img_idct = idct_2d(img_dct * mask)\n",
    "            img_idct = V(img_idct, requires_grad=True)\n",
    "            img = img_idct\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        # adversarial translation        \n",
    "        adv = netG(img)\n",
    "        adv = torch.min(torch.max(adv, img - args.eps/255.0), img + args.eps/255.0)\n",
    "        adv = torch.clamp(adv, 0.0, 1.0)\n",
    "        \n",
    "\n",
    "        # if args.FA:\n",
    "        #     gauss = (torch.randn(img.size()[0], 3, img_size, img_size) * (args.sigma / 255)).to(device)\n",
    "        #     mask = (torch.rand_like(img) * 2 * args.rho + 1 - args.rho).to(device)\n",
    "            \n",
    "        #     img_dct = dct_2d(img + gauss).to(device)\n",
    "        #     img_idct = idct_2d(img_dct * mask)\n",
    "        #     img_idct = V(img_idct, requires_grad=True)\n",
    "        #     img = img_idct\n",
    "            \n",
    "        #     adv_dct = dct_2d(adv + gauss).to(device)\n",
    "        #     adv_idct = idct_2d(adv_dct * mask)\n",
    "        #     adv_idct = V(adv_idct, requires_grad=True)\n",
    "        #     adv = adv_idct\n",
    "        # else:\n",
    "        #     pass\n",
    "        \n",
    "        if args.RN:\n",
    "            mean = np.random.normal(0.50, 0.08) # default=(0.50, 0.08) \n",
    "            std = np.random.normal(0.75, 0.08) # default=(0.75, 0.08)\n",
    "            adv_out_slice = model(normalize(adv.clone(), mean, std))[layer_idx]\n",
    "            img_out_slice = model(normalize(img.clone(), mean, std))[layer_idx]\n",
    "        else:\n",
    "            adv_out_slice = model(default_normalize(adv.clone()))[layer_idx]\n",
    "            img_out_slice = model(default_normalize(img.clone()))[layer_idx]\n",
    "        \n",
    "        if args.DA:\n",
    "            attention = abs(torch.mean(img_out_slice, dim=1, keepdim=True)).detach()\n",
    "        else:\n",
    "            attention = torch.ones(adv_out_slice.shape).cuda()\n",
    "            \n",
    "        loss = torch.cosine_similarity((adv_out_slice*attention).reshape(adv_out_slice.shape[0], -1), \n",
    "                                       (img_out_slice*attention).reshape(img_out_slice.shape[0], -1)).mean()\n",
    "        loss.backward()\n",
    "        optimG.step()\n",
    "        \n",
    "        # Every 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            logger.info('Epoch: {0} \\t Batch: {1} \\t loss: {2:.5f}'.format(epoch, i, running_loss/100))\n",
    "            running_loss = 0\n",
    "        running_loss += abs(loss.item())\n",
    "        \n",
    "        # Every 1 epoch\n",
    "        \n",
    "        if args.iter_ckpt:\n",
    "            if i % args.iter == 0 and i > 0:\n",
    "                save_path = os.path.join(save_checkpoint_dir, 'netG_{}_{}_{}.pth'.format(save_checkpoint_suffix, epoch, i))\n",
    "            \n",
    "                if isinstance(netG, nn.DataParallel):\n",
    "                    torch.save(netG.module.state_dict(), save_path)\n",
    "                else:\n",
    "                    torch.save(netG.state_dict(), save_path)\n",
    "                \n",
    "        else:\n",
    "            if i % 80000 == 0 and i > 0: # 1epoch=80000batch                        \n",
    "                save_path = os.path.join(save_checkpoint_dir, 'netG_{}_{}.pth'.format(save_checkpoint_suffix, epoch))\n",
    "    \n",
    "                if isinstance(netG, nn.DataParallel):\n",
    "                    torch.save(netG.module.state_dict(), save_path)\n",
    "                else:\n",
    "                    torch.save(netG.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15 (default, Nov 24 2022, 21:12:53) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15a5ed91507c36eb248011b7d4b42840e9d47d02750f359633e20bb6b8b69add"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
