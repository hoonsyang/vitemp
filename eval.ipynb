{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# public\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# custom\n",
    "from DCL_finegrained import model\n",
    "from utee import selector\n",
    "from utee.Normalize import Normalize\n",
    "from loader_checkpoint import *\n",
    "\n",
    "# logging\n",
    "# import logging, json\n",
    "# with open(\"logging_config.json\", \"rt\") as file:\n",
    "#     config = json.load(file)\n",
    "# logging.config.dictConfig(config)\n",
    "# logger = logging.getLogger()\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ArgumentParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(DA=False, FA=False, RN=False, epochs=0, eps=10, iter=10000, iter_ckpt=False, model_type='vgg16')\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Transferable Perturbation via Frequency Manipulation')\n",
    "parser.add_argument('--epochs', type=int, default=0, help='Model checkpoint epoch number')\n",
    "parser.add_argument('--eps', type=int, default=10, help='Perturbation budget (0~255)')\n",
    "parser.add_argument('--model_type', type=str, default='vgg16', help='Victim model: vgg16, vgg19, res152, dense169')\n",
    "parser.add_argument('--RN', type=lambda x: (str(x).lower() == 'true'), default=False, help='If true, activating the Random Normalization module in training phase')\n",
    "parser.add_argument('--DA', type=lambda x: (str(x).lower() == 'true'), default=False, help='If true, activating the Domain-agnostic Attention module in training phase')\n",
    "parser.add_argument('--FA', type=lambda x: (str(x).lower() == 'true'), default=False, help='If true, activating the Frequency Augmentation module in training phase')\n",
    "parser.add_argument('--iter_ckpt', type=lambda x: (str(x).lower() == 'true'), default=False, help='If true, Model checkpoint with iteration number')\n",
    "parser.add_argument('--iter', type=int, default=10000, help='Model checkpoint iteration number')\n",
    "args = parser.parse_args(args=[])\n",
    "print(args)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dcl_car']\n"
     ]
    }
   ],
   "source": [
    "# Choose the domain sets for evaluating the cross-domain transferability\n",
    "domain_list = ['cifar10', 'cifar100', 'stl10', 'svhn', 'dcl_dub', 'dcl_car', 'dcl_air', 'imagenet', 'imagenet_incv3']\n",
    "domain_selected = domain_list[:4]\n",
    "# domain_selected = domain_list[-2:-1] # imagenet\n",
    "# domain_selected = domain_list[-3:-2] # dcl_air\n",
    "domain_selected = domain_list[-4:-3] # dcl_car\n",
    "print(domain_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== dcl_car ==============================\n",
      "resnet50\n",
      "senet154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/senet154-c7b49a05.pth\" to /home/vilab/.cache/torch/hub/checkpoints/senet154-c7b49a05.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea055093c914e9eb81154ed4e7b88f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "se_resnet101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnet101-7e38fcc6.pth\" to /home/vilab/.cache/torch/hub/checkpoints/se_resnet101-7e38fcc6.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d33b377fd14baea906f4b793262f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/189M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data length: 8041\n",
      "Substitute Model: vgg16 \t RN: False \t DA: False \t FA: False \t Saving instance: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/vilab/anaconda3/envs/bia/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/vilab/anaconda3/envs/bia/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/vilab/anaconda3/envs/bia/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/vilab/yhm/Beyond-ImageNet-Attack/DCL_finegrained/dataset_DCL.py\", line 73, in __getitem__\n    img = self.pil_loader(img_path)\n  File \"/home/vilab/yhm/Beyond-ImageNet-Attack/DCL_finegrained/dataset_DCL.py\", line 112, in pil_loader\n    with open(imgpath, 'rb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/home/vilab/yhm/dataset/STCAR/cars_test/000046.jpg'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12885/3775122753.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Evaluation loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bia/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bia/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bia/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bia/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bia/lib/python3.7/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/vilab/anaconda3/envs/bia/lib/python3.7/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/vilab/anaconda3/envs/bia/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/vilab/anaconda3/envs/bia/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/vilab/yhm/Beyond-ImageNet-Attack/DCL_finegrained/dataset_DCL.py\", line 73, in __getitem__\n    img = self.pil_loader(img_path)\n  File \"/home/vilab/yhm/Beyond-ImageNet-Attack/DCL_finegrained/dataset_DCL.py\", line 112, in pil_loader\n    with open(imgpath, 'rb') as f:\nFileNotFoundError: [Errno 2] No such file or directory: '/home/vilab/yhm/dataset/STCAR/cars_test/000046.jpg'\n"
     ]
    }
   ],
   "source": [
    "for domain in domain_selected:\n",
    "    print('='*30, '{}'.format(domain), \"=\"*30)\n",
    "    \n",
    "    # Load the victim model (imagenet)\n",
    "    if domain[:3] == 'dcl': # CUB-200-2011, Stanford Cars, FGVC Aircraft\n",
    "        batch_size = 6\n",
    "        if domain == 'dcl_cub':\n",
    "            numcls = 200\n",
    "        elif domain == 'dcl_car':\n",
    "            numcls = 196\n",
    "        elif domain == 'dlc_air':\n",
    "            numcls = 100\n",
    "    elif domain == 'imagenet_incv3':\n",
    "        batch_size = 16\n",
    "    elif domain == 'imagenet':\n",
    "        batch_size = 32\n",
    "        mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "        model_vgg16 = nn.Sequential(Normalize(mean,std), torchvision.models.vgg16(pretrained=True)).cuda().eval()\n",
    "        model_vgg19 = nn.Sequential(Normalize(mean,std), torchvision.models.vgg19(pretrained=True)).cuda().eval()\n",
    "        model_res50 = nn.Sequential(Normalize(mean,std), torchvision.models.resnet50(pretrained=True)).cuda().eval()\n",
    "        model_res152 = nn.Sequential(Normalize(mean,std), torchvision.models.resnet152(pretrained=True)).cuda().eval()\n",
    "        model_dense121 = nn.Sequential(Normalize(mean,std), torchvision.models.densenet121(pretrained=True)).cuda().eval()\n",
    "        model_dense169 = nn.Sequential(Normalize(mean,std), torchvision.models.densenet169(pretrained=True)).cuda().eval()\n",
    "    else: # CIFAR-10, CIFAR-100, STL-10, SVHN\n",
    "        batch_size = 128\n",
    "    \n",
    "    # Load the validation dataset & victim model (others)\n",
    "    if domain == 'imagenet':\n",
    "        ds_fetcher, is_imagenet = selector.select(domain)\n",
    "    elif domain[:3] == 'dcl': # CUB-200-2011, Stanford Cars, FGVC Aircraft\n",
    "        model_res50, model_senet, model_seres101, ds_fetcher, is_imagenet = selector.select(domain)\n",
    "        acc_res50, clean_res50, acc_senet, clean_senet, acc_seres101, clean_seres101 = 0,0,0,0,0,0\n",
    "    else:  # CIFAR-10, CIFAR-100, STL-10, SVHN\n",
    "        model_raw, ds_fetcher, is_imagenet = selector.select(domain)\n",
    "        \n",
    "    if domain[-5:] == 'incv3':\n",
    "        ds_val = ds_fetcher(batch_size=batch_size, input_size=299, train=False, val=True)\n",
    "        data_length = len(ds_fetcher(batch_size=1, train=False, val=True))\n",
    "    else:\n",
    "        ds_val = ds_fetcher(batch_size=batch_size, train=False, val=True)\n",
    "        data_length = len(ds_fetcher(batch_size=1, train=False, val=True))\n",
    "    print('Validation data length:', data_length)\n",
    "    \n",
    "    \n",
    "    # Load the generative model (attacker)\n",
    "    netG = load_gan(args, domain).cuda().eval()\n",
    "    \n",
    "    # Initialize the classification accuracy (clean & attack)\n",
    "    clean_vgg16, clean_vgg19, clean_res50, clean_res152, clean_dense121, clean_dense169 = 0,0,0,0,0,0\n",
    "    acc_vgg16, acc_vgg19, acc_res50, acc_res152, acc_dense121, acc_dense169 = 0,0,0,0,0,0\n",
    "    clean, accuracy = 0, 0\n",
    "    \n",
    "    # Evaluation loop\n",
    "    for i, data_val in tqdm(enumerate(ds_val)):\n",
    "        img, label = data_val\n",
    "        img = Variable(torch.FloatTensor(img)).cuda()\n",
    "        label = Variable(torch.from_numpy(np.array(label)).long().cuda())\n",
    "        adv = netG(img)\n",
    "\n",
    "        # projection\n",
    "        adv = torch.min(torch.max(adv, img - args.eps/255.0), img + args.eps/255.0)\n",
    "        adv = torch.clamp(adv, 0.0, 1.0)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            if domain == 'imagenet':\n",
    "                clean_vgg16 += torch.sum(torch.argmax(model_vgg16(img), dim=1) == label.cuda())\n",
    "                acc_vgg16 += torch.sum(torch.argmax(model_vgg16(adv), dim=1) == label.cuda())\n",
    "                \n",
    "                clean_vgg19 += torch.sum(torch.argmax(model_vgg19(img), dim=1) == label.cuda())\n",
    "                acc_vgg19 += torch.sum(torch.argmax(model_vgg19(adv), dim=1) == label.cuda())\n",
    "                \n",
    "                clean_res50 += torch.sum(torch.argmax(model_res50(img), dim=1) == label.cuda())\n",
    "                acc_res50 += torch.sum(torch.argmax(model_res50(adv), dim=1) == label.cuda())\n",
    "                \n",
    "                clean_res152 += torch.sum(torch.argmax(model_res152(img), dim=1) == label.cuda())\n",
    "                acc_res152 += torch.sum(torch.argmax(model_res152(adv), dim=1) == label.cuda())\n",
    "                \n",
    "                clean_dense121 += torch.sum(torch.argmax(model_dense121(img), dim=1) == label.cuda())\n",
    "                acc_dense121 += torch.sum(torch.argmax(model_dense121(adv), dim=1) == label.cuda())\n",
    "                \n",
    "                clean_dense169 += torch.sum(torch.argmax(model_dense169(img), dim=1) == label.cuda())\n",
    "                acc_dense169 += torch.sum(torch.argmax(model_dense169(adv), dim=1) == label.cuda())\n",
    "            \n",
    "            elif domain[:3] != 'dcl': # CIFAR-10, CIFAR-100, STL-10, SVHN\n",
    "                clean += torch.sum(torch.argmax(model_raw(img), dim=1) == label.cuda())\n",
    "                accuracy += torch.sum(torch.argmax(model_raw(adv), dim=1) == label.cuda())\n",
    "                \n",
    "            else: # CUB-200-2011, Stanford Cars, FGVC Aircraft\n",
    "                outputs = model_res50(adv)\n",
    "                outputs_clean = model_res50(img)\n",
    "                outputs_pred = outputs[0] + outputs[1][:,0:numcls] + outputs[1][:,numcls:2*numcls]\n",
    "                outputs_pred_clean = outputs_clean[0] + outputs_clean[1][:,0:numcls] + outputs_clean[1][:,numcls:2*numcls]\n",
    "                acc_res50 += torch.sum(torch.argmax(outputs_pred, dim=1) == label.cuda())\n",
    "                clean_res50 += torch.sum(torch.argmax(outputs_pred_clean, dim=1) == label.cuda())\n",
    "                \n",
    "                outputs2 = model_senet(adv)\n",
    "                outputs_clean2 = model_senet(img)\n",
    "                outputs_pred2 = outputs2[0] + outputs2[1][:,0:numcls] + outputs2[1][:,numcls:2*numcls]\n",
    "                outputs_pred_clean2 = outputs_clean2[0] + outputs_clean2[1][:,0:numcls] + outputs_clean2[1][:,numcls:2*numcls]\n",
    "                acc_senet += torch.sum(torch.argmax(outputs_pred2, dim=1) == label.cuda())\n",
    "                clean_senet += torch.sum(torch.argmax(outputs_pred_clean2, dim=1) == label.cuda())\n",
    "                \n",
    "                outputs3 = model_seres101(adv)\n",
    "                outputs_clean3 = model_seres101(img)\n",
    "                outputs_pred3 = outputs3[0] + outputs3[1][:,0:numcls] + outputs3[1][:,numcls:2*numcls]\n",
    "                outputs_pred_clean3 = outputs_clean3[0] + outputs_clean3[1][:,0:numcls] + outputs_clean3[1][:,numcls:2*numcls]\n",
    "                acc_seres101 += torch.sum(torch.argmax(outputs_pred3, dim=1) == label.cuda())\n",
    "                clean_seres101 += torch.sum(torch.argmax(outputs_pred_clean3, dim=1) == label.cuda())\n",
    "        \n",
    "    if domain == 'imagenet':\n",
    "        print('----------------vgg16----------------')\n",
    "        print(clean_vgg16 / data_length)\n",
    "        print(acc_vgg16 / data_length)\n",
    "        print('----------------vgg19----------------')\n",
    "        print(clean_vgg19 / data_length)\n",
    "        print(acc_vgg19 / data_length)\n",
    "        print('----------------res50----------------')\n",
    "        print(clean_res50 / data_length)\n",
    "        print(acc_res50 / data_length)      \n",
    "        print('----------------res152----------------')\n",
    "        print(clean_res152 / data_length)\n",
    "        print(acc_res152 / data_length)\n",
    "        print('----------------dense121----------------')\n",
    "        print(clean_dense121 / data_length)\n",
    "        print(acc_dense121 / data_length)\n",
    "        print('----------------dense169----------------')\n",
    "        print(clean_dense169 / data_length)\n",
    "        print(acc_dense169 / data_length)\n",
    "        \n",
    "    elif domain[:3] == 'dcl': # CUB-200-2011, Stanford Cars, FGVC Aircraft\n",
    "        print('----------------backbone:res50----------------')\n",
    "        print(clean_res50 / data_length)\n",
    "        print(acc_res50 / data_length)\n",
    "        print('----------------backbone:se-net----------------')\n",
    "        print(clean_senet / data_length)\n",
    "        print(acc_senet / data_length)\n",
    "        print('----------------backbone:se-res101----------------')\n",
    "        print(clean_seres101 / data_length)\n",
    "        print(acc_seres101 / data_length)\n",
    "\n",
    "    else: # CIFAR-10, CIFAR-100, STL-10, SVHN\n",
    "        print(clean / data_length)\n",
    "        print(accuracy / data_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GT\n",
    "netG_BIA_9.pth\n",
    "============================== cifar10 ==============================\n",
    "Building and initializing cifar10 parameters\n",
    "Building CIFAR-10 data loader with 1 workers\n",
    "Files already downloaded and verified\n",
    "Building CIFAR-10 data loader with 1 workers\n",
    "Files already downloaded and verified\n",
    "Validation data length: 10000\n",
    "Substitute Model: vgg16 \t RN: False \t DA: False \t FA: False \t Saving instance: 9\n",
    "79it [00:26,  2.96it/s]\n",
    "tensor(0.9378, device='cuda:0')\n",
    "tensor(0.5649, device='cuda:0')\n",
    "============================== cifar100 ==============================\n",
    "Building and initializing cifar100 parameters\n",
    "Building CIFAR-100 data loader with 1 workers\n",
    "Files already downloaded and verified\n",
    "Building CIFAR-100 data loader with 1 workers\n",
    "Files already downloaded and verified\n",
    "Validation data length: 10000\n",
    "Substitute Model: vgg16 \t RN: False \t DA: False \t FA: False \t Saving instance: 9\n",
    "79it [00:03, 21.14it/s]\n",
    "tensor(0.7427, device='cuda:0')\n",
    "tensor(0.2203, device='cuda:0')\n",
    "============================== stl10 ==============================\n",
    "Building and initializing stl10 parameters\n",
    "Building STL10 data loader with 1 workers\n",
    "Files already downloaded and verified\n",
    "Building STL10 data loader with 1 workers\n",
    "Files already downloaded and verified\n",
    "Validation data length: 8000\n",
    "Substitute Model: vgg16 \t RN: False \t DA: False \t FA: False \t Saving instance: 9\n",
    "63it [00:03, 18.60it/s]\n",
    "tensor(0.7759, device='cuda:0')\n",
    "tensor(0.7005, device='cuda:0')\n",
    "============================== svhn ==============================\n",
    "Building and initializing svhn parameters\n",
    "Building SVHN data loader with 1 workers\n",
    "Using downloaded and verified file: ./public_dataset/pytorch/svhn-data/test_32x32.mat\n",
    "Building SVHN data loader with 1 workers\n",
    "Using downloaded and verified file: ./public_dataset/pytorch/svhn-data/test_32x32.mat\n",
    "Validation data length: 26032\n",
    "Substitute Model: vgg16 \t RN: False \t DA: False \t FA: False \t Saving instance: 9\n",
    "204it [00:06, 32.07it/s]\n",
    "tensor(0.9603, device='cuda:0')\n",
    "tensor(0.9046, device='cuda:0')\n",
    "============================== imagenet ==============================\n",
    "Building and initializing imagenet parameters\n",
    "Building IMAGENET data loader, 50000 for train, 50000 for test\n",
    "Building IMAGENET data loader, 50000 for train, 50000 for test\n",
    "Validation data length: 50000\n",
    "Substitute Model: vgg16 \t RN: False \t DA: False \t FA: False \t Saving instance: 9\n",
    "1563it [14:46,  1.76it/s]\n",
    "----------------vgg16----------------\n",
    "tensor(0.7014, device='cuda:0')\n",
    "tensor(0.0133, device='cuda:0')\n",
    "----------------vgg19----------------\n",
    "tensor(0.7095, device='cuda:0')\n",
    "tensor(0.0310, device='cuda:0')\n",
    "----------------res50----------------\n",
    "tensor(0.7460, device='cuda:0')\n",
    "tensor(0.2396, device='cuda:0')\n",
    "----------------res152----------------\n",
    "tensor(0.7734, device='cuda:0')\n",
    "tensor(0.4146, device='cuda:0')\n",
    "----------------dense121----------------\n",
    "tensor(0.7422, device='cuda:0')\n",
    "tensor(0.2464, device='cuda:0')\n",
    "----------------dense169----------------\n",
    "tensor(0.7575, device='cuda:0')\n",
    "tensor(0.3069, device='cuda:0')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Iterative training : 1 normal batch , 1 FA batch, 1 normal batch, ...\n",
    "netG_BIA+FA_0.pth   # 1epoch\n",
    "\n",
    "============================== cifar10 ==============================\n",
    "Building and initializing cifar10 parameters\n",
    "Building CIFAR-10 data loader with 1 workers\n",
    "Files already downloaded and verified\n",
    "Building CIFAR-10 data loader with 1 workers\n",
    "Files already downloaded and verified\n",
    "Validation data length: 10000\n",
    "Substitute Model: vgg16 \t RN: False \t DA: False \t FA: True \t Saving instance: 0\n",
    "79it [00:28,  2.79it/s]\n",
    "tensor(0.9378, device='cuda:0')\n",
    "tensor(0.5676, device='cuda:0')\n",
    "============================== cifar100 ==============================\n",
    "Building and initializing cifar100 parameters\n",
    "Building CIFAR-100 data loader with 1 workers\n",
    "Files already downloaded and verified\n",
    "Building CIFAR-100 data loader with 1 workers\n",
    "Files already downloaded and verified\n",
    "Validation data length: 10000\n",
    "Substitute Model: vgg16 \t RN: False \t DA: False \t FA: True \t Saving instance: 0\n",
    "79it [00:03, 21.71it/s]\n",
    "tensor(0.7427, device='cuda:0')\n",
    "tensor(0.2350, device='cuda:0')\n",
    "============================== stl10 ==============================\n",
    "Building and initializing stl10 parameters\n",
    "Building STL10 data loader with 1 workers\n",
    "Files already downloaded and verified\n",
    "Building STL10 data loader with 1 workers\n",
    "Files already downloaded and verified\n",
    "Validation data length: 8000\n",
    "Substitute Model: vgg16 \t RN: False \t DA: False \t FA: True \t Saving instance: 0\n",
    "63it [00:03, 17.23it/s]\n",
    "tensor(0.7759, device='cuda:0')\n",
    "tensor(0.6859, device='cuda:0')\n",
    "============================== svhn ==============================\n",
    "Building and initializing svhn parameters\n",
    "Building SVHN data loader with 1 workers\n",
    "Using downloaded and verified file: ./public_dataset/pytorch/svhn-data/test_32x32.mat\n",
    "Building SVHN data loader with 1 workers\n",
    "Using downloaded and verified file: ./public_dataset/pytorch/svhn-data/test_32x32.mat\n",
    "Validation data length: 26032\n",
    "Substitute Model: vgg16 \t RN: False \t DA: False \t FA: True \t Saving instance: 0\n",
    "204it [00:06, 31.70it/s]\n",
    "tensor(0.9603, device='cuda:0')\n",
    "tensor(0.8544, device='cuda:0')\n",
    "============================== imagenet ==============================\n",
    "Building and initializing imagenet parameters\n",
    "Building IMAGENET data loader, 50000 for train, 50000 for test\n",
    "Building IMAGENET data loader, 50000 for train, 50000 for test\n",
    "Validation data length: 50000\n",
    "Substitute Model: vgg16 \t RN: False \t DA: False \t FA: True \t Saving instance: 0\n",
    "143it [01:41,  1.72it/s]\n",
    "----------------vgg16----------------\n",
    "tensor(0.7014, device='cuda:0')\n",
    "tensor(0.0264, device='cuda:0')\n",
    "----------------vgg19----------------\n",
    "tensor(0.7095, device='cuda:0')\n",
    "tensor(0.0505, device='cuda:0')\n",
    "----------------res50----------------\n",
    "tensor(0.7460, device='cuda:0')\n",
    "tensor(0.2480, device='cuda:0')\n",
    "----------------res152----------------\n",
    "tensor(0.7734, device='cuda:0')\n",
    "tensor(0.3985, device='cuda:0')\n",
    "----------------dense121----------------\n",
    "tensor(0.7422, device='cuda:0')\n",
    "tensor(0.2855, device='cuda:0')\n",
    "----------------dense169----------------\n",
    "tensor(0.7575, device='cuda:0')\n",
    "tensor(0.3547, device='cuda:0')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "netG_BIA+FA_0_10000.pth     # 1 epoch + 10000 iterations \n",
    "\n",
    "============================== cifar10 ==============================\n",
    "Building and initializing cifar10 parameters\n",
    "Building CIFAR-10 data loader with 1 workers\n",
    "Files already downloaded and verified\n",
    "Building CIFAR-10 data loader with 1 workers\n",
    "Files already downloaded and verified\n",
    "Validation data length: 10000\n",
    "Substitute Model: vgg16 \t RN: False \t DA: False \t FA: True \t Saving instance: 0\n",
    "79it [00:03, 21.03it/s]\n",
    "tensor(0.9378, device='cuda:0')\n",
    "tensor(0.5524, device='cuda:0')\n",
    "============================== cifar100 ==============================\n",
    "Building and initializing cifar100 parameters\n",
    "Building CIFAR-100 data loader with 1 workers\n",
    "Files already downloaded and verified\n",
    "Building CIFAR-100 data loader with 1 workers\n",
    "Files already downloaded and verified\n",
    "Validation data length: 10000\n",
    "Substitute Model: vgg16 \t RN: False \t DA: False \t FA: True \t Saving instance: 0\n",
    "79it [00:03, 20.52it/s]\n",
    "tensor(0.7427, device='cuda:0')\n",
    "tensor(0.2303, device='cuda:0')\n",
    "============================== stl10 ==============================\n",
    "Building and initializing stl10 parameters\n",
    "Building STL10 data loader with 1 workers\n",
    "Files already downloaded and verified\n",
    "Building STL10 data loader with 1 workers\n",
    "Files already downloaded and verified\n",
    "Validation data length: 8000\n",
    "Substitute Model: vgg16 \t RN: False \t DA: False \t FA: True \t Saving instance: 0\n",
    "63it [00:03, 20.02it/s]\n",
    "tensor(0.7759, device='cuda:0')\n",
    "tensor(0.6795, device='cuda:0')\n",
    "============================== svhn ==============================\n",
    "Building and initializing svhn parameters\n",
    "Building SVHN data loader with 1 workers\n",
    "Using downloaded and verified file: ./public_dataset/pytorch/svhn-data/test_32x32.mat\n",
    "Building SVHN data loader with 1 workers\n",
    "Using downloaded and verified file: ./public_dataset/pytorch/svhn-data/test_32x32.mat\n",
    "Validation data length: 26032\n",
    "Substitute Model: vgg16 \t RN: False \t DA: False \t FA: True \t Saving instance: 0\n",
    "204it [00:06, 30.75it/s]\n",
    "tensor(0.9603, device='cuda:0')\n",
    "tensor(0.8762, device='cuda:0')\n",
    "============================== imagenet ==============================\n",
    "Building and initializing imagenet parameters\n",
    "Building IMAGENET data loader, 50000 for train, 50000 for test\n",
    "1563it [14:44,  1.77it/s]\n",
    "----------------vgg16----------------\n",
    "tensor(0.7014, device='cuda:0')\n",
    "tensor(0.0245, device='cuda:0')\n",
    "----------------vgg19----------------\n",
    "tensor(0.7095, device='cuda:0')\n",
    "tensor(0.0479, device='cuda:0')\n",
    "----------------res50----------------\n",
    "tensor(0.7460, device='cuda:0')\n",
    "tensor(0.2529, device='cuda:0')\n",
    "----------------res152----------------\n",
    "tensor(0.7734, device='cuda:0')\n",
    "tensor(0.4097, device='cuda:0')\n",
    "----------------dense121----------------\n",
    "tensor(0.7422, device='cuda:0')\n",
    "tensor(0.2871, device='cuda:0')\n",
    "----------------dense169----------------\n",
    "tensor(0.7575, device='cuda:0')\n",
    "tensor(0.3600, device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15 (default, Nov 24 2022, 21:12:53) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "15a5ed91507c36eb248011b7d4b42840e9d47d02750f359633e20bb6b8b69add"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
